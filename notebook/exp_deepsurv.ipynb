{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入模拟数据\n",
    "\n",
    "使用模拟数据，测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "os.chdir(\"/home/num_24/桌面/mywork/github/TFDeepSurv\")\n",
    "os.getcwd()\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "from dataset import SimulatedData\n",
    "import LDeepSurv as LDS\n",
    "\n",
    "data_config = SimulatedData(10000, num_features = 9)\n",
    "data = data_config.generate_data(2000)\n",
    "sort_idx = np.argsort(data['t'])[::-1]\n",
    "data['x'] = data['x'] [sort_idx]\n",
    "data['e'] = data['e'] [sort_idx]\n",
    "data['t'] = data['t'] [sort_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:  9\n",
      "-------------------------------------------------\n",
      "training steps 1: loss=9681.19.\n",
      "\n",
      "CI on train set: 0.493198.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 51: loss=9681.15.\n",
      "\n",
      "CI on train set: 0.499988.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 101: loss=9681.1.\n",
      "\n",
      "CI on train set: 0.504897.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 151: loss=9681.01.\n",
      "\n",
      "CI on train set: 0.507577.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 201: loss=9680.78.\n",
      "\n",
      "CI on train set: 0.509831.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 251: loss=9680.01.\n",
      "\n",
      "CI on train set: 0.512087.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 301: loss=9676.3.\n",
      "\n",
      "CI on train set: 0.515305.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 351: loss=9558.02.\n",
      "\n",
      "CI on train set: 0.532579.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 401: loss=9619.41.\n",
      "\n",
      "CI on train set: 0.61052.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 451: loss=9385.28.\n",
      "\n",
      "CI on train set: 0.712781.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 501: loss=9373.83.\n",
      "\n",
      "CI on train set: 0.716586.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 551: loss=9371.8.\n",
      "\n",
      "CI on train set: 0.716814.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 601: loss=9369.63.\n",
      "\n",
      "CI on train set: 0.717464.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 651: loss=9364.79.\n",
      "\n",
      "CI on train set: 0.718773.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 701: loss=9358.34.\n",
      "\n",
      "CI on train set: 0.720153.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 751: loss=9352.05.\n",
      "\n",
      "CI on train set: 0.720759.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 801: loss=9342.25.\n",
      "\n",
      "CI on train set: 0.722642.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 851: loss=9334.71.\n",
      "\n",
      "CI on train set: 0.725361.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 901: loss=9325.34.\n",
      "\n",
      "CI on train set: 0.728713.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 951: loss=9317.69.\n",
      "\n",
      "CI on train set: 0.73125.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 1001: loss=9600.09.\n",
      "\n",
      "CI on train set: 0.714017.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 1051: loss=8603.71.\n",
      "\n",
      "CI on train set: 0.843947.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 1101: loss=8521.6.\n",
      "\n",
      "CI on train set: 0.844865.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 1151: loss=8443.06.\n",
      "\n",
      "CI on train set: 0.850661.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 1201: loss=8533.98.\n",
      "\n",
      "CI on train set: 0.845288.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 1251: loss=8590.66.\n",
      "\n",
      "CI on train set: 0.827348.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 1301: loss=8455.9.\n",
      "\n",
      "CI on train set: 0.847324.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 1351: loss=8681.01.\n",
      "\n",
      "CI on train set: 0.82008.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 1401: loss=8544.66.\n",
      "\n",
      "CI on train set: 0.835821.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 1451: loss=8424.72.\n",
      "\n",
      "CI on train set: 0.852865.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 1501: loss=8393.55.\n",
      "\n",
      "CI on train set: 0.853932.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 1551: loss=8452.64.\n",
      "\n",
      "CI on train set: 0.846633.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 1601: loss=8429.92.\n",
      "\n",
      "CI on train set: 0.846578.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 1651: loss=8476.41.\n",
      "\n",
      "CI on train set: 0.851751.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 1701: loss=8405.69.\n",
      "\n",
      "CI on train set: 0.852282.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 1751: loss=8399.82.\n",
      "\n",
      "CI on train set: 0.854427.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 1801: loss=8396.06.\n",
      "\n",
      "CI on train set: 0.850833.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 1851: loss=8491.21.\n",
      "\n",
      "CI on train set: 0.844554.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 1901: loss=8416.44.\n",
      "\n",
      "CI on train set: 0.85319.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 1951: loss=8385.75.\n",
      "\n",
      "CI on train set: 0.852534.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 2001: loss=8363.37.\n",
      "\n",
      "CI on train set: 0.856934.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 2051: loss=8477.66.\n",
      "\n",
      "CI on train set: 0.844334.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 2101: loss=8404.42.\n",
      "\n",
      "CI on train set: 0.851756.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 2151: loss=8344.72.\n",
      "\n",
      "CI on train set: 0.856983.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 2201: loss=8384.63.\n",
      "\n",
      "CI on train set: 0.855393.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 2251: loss=8420.79.\n",
      "\n",
      "CI on train set: 0.851286.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 2301: loss=8394.77.\n",
      "\n",
      "CI on train set: 0.852144.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 2351: loss=8408.86.\n",
      "\n",
      "CI on train set: 0.848273.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 2401: loss=8434.73.\n",
      "\n",
      "CI on train set: 0.850526.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 2451: loss=8573.56.\n",
      "\n",
      "CI on train set: 0.835011.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 2501: loss=8380.48.\n",
      "\n",
      "CI on train set: 0.859044.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 2551: loss=8355.36.\n",
      "\n",
      "CI on train set: 0.857972.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 2601: loss=8352.96.\n",
      "\n",
      "CI on train set: 0.854498.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 2651: loss=8365.68.\n",
      "\n",
      "CI on train set: 0.852541.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 2701: loss=8352.34.\n",
      "\n",
      "CI on train set: 0.85612.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 2751: loss=8325.47.\n",
      "\n",
      "CI on train set: 0.858865.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 2801: loss=8328.86.\n",
      "\n",
      "CI on train set: 0.858492.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 2851: loss=8383.82.\n",
      "\n",
      "CI on train set: 0.853447.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 2901: loss=8399.57.\n",
      "\n",
      "CI on train set: 0.860723.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 2951: loss=8408.49.\n",
      "\n",
      "CI on train set: 0.852395.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 3001: loss=8383.16.\n",
      "\n",
      "CI on train set: 0.85533.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 3051: loss=8354.44.\n",
      "\n",
      "CI on train set: 0.85385.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 3101: loss=8343.54.\n",
      "\n",
      "CI on train set: 0.859132.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 3151: loss=8379.43.\n",
      "\n",
      "CI on train set: 0.853522.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 3201: loss=8377.93.\n",
      "\n",
      "CI on train set: 0.854646.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 3251: loss=8373.75.\n",
      "\n",
      "CI on train set: 0.853779.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 3301: loss=8331.85.\n",
      "\n",
      "CI on train set: 0.855586.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 3351: loss=8349.73.\n",
      "\n",
      "CI on train set: 0.853741.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 3401: loss=8350.17.\n",
      "\n",
      "CI on train set: 0.853483.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 3451: loss=8317.21.\n",
      "\n",
      "CI on train set: 0.859932.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 3501: loss=8364.13.\n",
      "\n",
      "CI on train set: 0.855652.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 3551: loss=8362.11.\n",
      "\n",
      "CI on train set: 0.855596.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 3601: loss=8360.7.\n",
      "\n",
      "CI on train set: 0.855693.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "training steps 3651: loss=8359.84.\n",
      "\n",
      "CI on train set: 0.855737.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 3701: loss=8359.2.\n",
      "\n",
      "CI on train set: 0.855757.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 3751: loss=8358.04.\n",
      "\n",
      "CI on train set: 0.855775.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 3801: loss=8363.82.\n",
      "\n",
      "CI on train set: 0.854884.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 3851: loss=8351.05.\n",
      "\n",
      "CI on train set: 0.856768.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 3901: loss=8371.73.\n",
      "\n",
      "CI on train set: 0.854943.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 3951: loss=8348.91.\n",
      "\n",
      "CI on train set: 0.856247.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 4001: loss=8340.02.\n",
      "\n",
      "CI on train set: 0.856335.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 4051: loss=8360.2.\n",
      "\n",
      "CI on train set: 0.855014.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 4101: loss=8352.23.\n",
      "\n",
      "CI on train set: 0.85702.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 4151: loss=8355.85.\n",
      "\n",
      "CI on train set: 0.856513.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 4201: loss=8338.49.\n",
      "\n",
      "CI on train set: 0.856749.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 4251: loss=8356.94.\n",
      "\n",
      "CI on train set: 0.856062.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 4301: loss=8349.41.\n",
      "\n",
      "CI on train set: 0.857291.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 4351: loss=8327.91.\n",
      "\n",
      "CI on train set: 0.857392.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 4401: loss=8335.51.\n",
      "\n",
      "CI on train set: 0.8579.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 4451: loss=8338.43.\n",
      "\n",
      "CI on train set: 0.856949.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 4501: loss=8334.06.\n",
      "\n",
      "CI on train set: 0.858413.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 4551: loss=8349.82.\n",
      "\n",
      "CI on train set: 0.856453.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 4601: loss=8342.37.\n",
      "\n",
      "CI on train set: 0.85737.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 4651: loss=8352.67.\n",
      "\n",
      "CI on train set: 0.856648.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 4701: loss=8335.45.\n",
      "\n",
      "CI on train set: 0.85718.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 4751: loss=8331.37.\n",
      "\n",
      "CI on train set: 0.858292.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 4801: loss=8330.51.\n",
      "\n",
      "CI on train set: 0.857529.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 4851: loss=8333.14.\n",
      "\n",
      "CI on train set: 0.85823.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 4901: loss=8337.\n",
      "\n",
      "CI on train set: 0.856953.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 4951: loss=8348.93.\n",
      "\n",
      "CI on train set: 0.856591.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_features = data['x'].shape[1]\n",
    "print(\"features: \", n_features)\n",
    "model = LDS.LDeepSurv(n_features, [7,5,3], 1, learning_rate=0.001, activation='tanh', L2_reg=0.01)\n",
    "\n",
    "model.train(data['x'], {'e': data['e'], 't': data['t']}, num_epoch=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.54264128 -0.95849609  0.26729646  0.49760777 -0.00298598 -0.55040669\n",
      "  -0.60387427  0.52106142 -0.66177833]\n",
      " [-0.82332039  0.37071964  0.90678668 -0.99210346  0.02438453  0.62524194\n",
      "   0.22505213  0.44351062 -0.41624787]\n",
      " [ 0.83554822  0.42915156  0.08508874 -0.71565992 -0.25331849  0.34826723\n",
      "  -0.11633365 -0.13197201  0.23553395]\n",
      " [ 0.02627649  0.30079436  0.20207791  0.61044639  0.0432943   0.81729776\n",
      "  -0.36152783 -0.81908131 -0.39859989]\n",
      " [-0.77203125  0.65736264 -0.90620738  0.25257429  0.09517231  0.638574\n",
      "  -0.6021049   0.71370059 -0.29669473]\n",
      " [ 0.5092954  -0.40807658  0.76787293 -0.34897673 -0.66996819 -0.21494152\n",
      "  -0.81307924  0.64221132 -0.69769597]\n",
      " [-0.2317711   0.88852143  0.97525096 -0.08739091  0.6522457  -0.49725172\n",
      "   0.19474329  0.80566353  0.0691159 ]\n",
      " [ 0.18040273 -0.92143649 -0.28563648 -0.84077382 -0.38908017 -0.33856139\n",
      "   0.54766059 -0.92008156 -0.14101565]\n",
      " [-0.37014624  0.2729823  -0.30730569 -0.91380531  0.75983036  0.52648115\n",
      "   0.75619328 -0.16498171  0.21115513]\n",
      " [ 0.02693325  0.1956733  -0.47556868 -0.39825737 -0.94920045 -0.39387488\n",
      "  -0.51584822  0.11515637  0.13101403]]\n",
      "[0 0 0 1 0 1 1 1 1 1]\n",
      "[  1.50000000e+01   1.50000000e+01   1.50000000e+01   1.18921861e-01\n",
      "   1.50000000e+01   2.71645713e+00   8.47861767e+00   4.81689739e+00\n",
      "   2.50029057e-01   8.09251913e-04]\n"
     ]
    }
   ],
   "source": [
    "N = 10\n",
    "print(data['x'][0:N])\n",
    "print(data['e'][0:N])\n",
    "print(data['t'][0:N])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1356"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data['e']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['e'].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:  9\n"
     ]
    }
   ],
   "source": [
    "n_features = data['x'].shape[1]\n",
    "print(\"features: \", n_features)\n",
    "model = LDeepSurv.LDeepSurv(n_features, [10, 5], 1, activation='tanh', L2_reg=0.001, L1_reg=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "training steps 1: loss=8943.11.\n",
      "\n",
      "CI on train set: 0.500538.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 21: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 41: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 61: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 81: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 101: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 121: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 141: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 161: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 181: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 201: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 221: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 241: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 261: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 281: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 301: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 321: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 341: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 361: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 381: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 401: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 421: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 441: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 461: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 481: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 501: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 521: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 541: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 561: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 581: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 601: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 621: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 641: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 661: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 681: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 701: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 721: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 741: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 761: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 781: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 801: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 821: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 841: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 861: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 881: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 901: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 921: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 941: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 961: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n",
      "-------------------------------------------------\n",
      "training steps 981: loss=8943.07.\n",
      "\n",
      "CI on train set: 0.501045.\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
